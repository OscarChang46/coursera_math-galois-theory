\section[Tensor product. Structure of finite $K$-algebras.]{Lecture Notes: 14 Mar -- 20 Mar}
We have been considering $[L:K]$ a finite field extension, and defined separability: If $L$ is generated over $K$ by a finite number of separable elements $\alpha_1,\dotsc,\alpha_r$, then the number of homomorphisms over $K$ from $L$ to an algebraic closure $\bar{K}$ is equal to the degree of $L$ over $K$. (In general, this number of homomorphisms is less than or equal to the degree.) We have called this number of homomorphisms the \term{separable degree} of $L$ over $K$.

If $L = K(\alpha)$, this was clear, as the homomorphisms took $\alpha$ to the other roots of the minimal polynomial. In general, one can use induction and the multiplicativity of the degree (which is just linear algebra) and the number of homomorphisms (theorem on extension of homomorphisms). A \term{separable extension} was just that which had the right number of homomorphisms.

We will characterize separability in terms of \term{tensor products}. This is a general digression that does not have much to do with field extensions.

\subsection{Definition of a tensor product.}
\begin{dfn}[Tensor product of modules]
Let $A$ be a ring, and $M$, $N$ be $A$-modules. The \term{tensor product} of $M$ and $N$ over $A$, denoted $M \tensor{A} N$, is another $A$-module together with an $A$-bilinear map $\phi: M \times N \to M \tensor{A} N$ with the following ``universal property'': If $P$ is any $A$-module and $f: M \times N \to P$ is $A$-bilinear (i.e. for any $m, n$, the maps $f_m: N \to P, n \mapsto f(m, n)$ and $f_n: M \to P, m \mapsto f(m, n)$ are homomorphisms of $A$-modules) then there exists a unique homomorphism of $A$-modules $\tilde{f}: M \tensor{A} N \to P$ such that $f = \tilde{f} \after \phi$.
\end{dfn}

This property characterizes the pair $(\phi, M \tensor{A} N)$. If $(\bar{\phi}, \overline{M \tensor{A} N})$ is another such pair, then by definition we have mutually inverse homomorphisms of $A$-modules between our tensor products $M \tensor{A} N$ and $\overline{M \tensor{A} N}$. So the uniqueness of tensor products follows directly from the definition, but of course the real question is: why does such a thing even exist?

We can give a construction as follows: Consider $\mc{E}$ the family of maps from $M \times N$ to $A$ \emph{as sets} which are zero almost everywhere, that is, outside of a finite set. (For example, delta-functions $\delta_{m,n}: M \times N \to A$, where $\delta_{m,n}(m, n) = 1$ and $\delta_{m,n}(m',n') = 0$ for all $(m', n') \neq (m, n)$.) This $\mc{E}$ is a \term{free} $A$-module with base $\delta_{m,n}$. Now, we have a map of sets $M \times N \to \mc{E}$ that sends $(m, n) \mapsto \delta_{m,n}$; this is not necessarily bilinear, but we can make it so. Take $\mc{F} \sbs \mc{E}$ a submodule generated by \[\delta_{m + m', n} - \delta_{m, n} - \delta_{m', n}, \delta_{m, n + n'} - \delta_{m, n} - \delta_{m, n'}, \delta_{am, n} - a \delta_{m, n}, \delta_{m, an} - a\delta_{m, n}\] Now the \emph{map to the quotient} $M \times N \to \mc{E} / \mc{F}$ is bilinear, and has the desired universal property.

\subsection{Tensor product of modules.}
If we have any bilinear map $M \times N \to P$, we can also define a map $\tilde{f}: \mc{E} \to P$ sending $\delta_{m, n} \mapsto f(m, n)$. When the map $f$ is bilinear, then the map from $\mc{E} \to P$ must factor through the quotient $\mc{E} / \mc{F}$, and moreover is zero on $\mc{F}$! So we can complete the diagram with the bilinear map $M \times N \to \mc{E}/\mc{F}$. We also have uniqueness since the map $\mc{E} \to P$ is determined by the images of $\delta_{m, n}$. We can then call the map from $M \times N \to \mc{E}/\mc{F}$ $\phi$, and identify $\mc{E}/\mc{F} = M \tensor{A} N$.

The tensor product $M \tensor{A} N$ is generated by the classes of $\delta_{m, n}$ modulo $\mc{F}$; we will denote them by $m \otimes n$.

\begin{rmk}
The tensor product is not equal to $\set{m \otimes n : m \in M, n \in N}$; we can write any $x \in M \tensor{A} N$ as a finite sum of symbols $\sum_{i = 1}^{n} m_i \otimes n_i$ but we cannot reduce further.
\end{rmk}

We might ask, why haven't we simply \emph{defined} the tensor product by this more explicit construction? Why are we talking about this ``universal property''? 
It turns out that the proofs become easier when we use the universal property.
For example, we want to show that $M \tensor{A} N \iso N \tensor{A} M$.
Indeed $M \times N \to N \tensor{A} M$ where $(m, n) \mapsto n \otimes m$ is bilinear; therefore we have $\alpha: M \tensor{A} N \to N \tensor{A} M$. In the same way we obtain the inverse map in the other direction.

The same type of argument yields, for example, that $A \tensor{A} M \iso M$.

More seriously, we have seen that the tensor product is generated by those ``little'' tensor products: If $M$ is generated by $\set{e_i}_{i = 1}^{n}$ and $N$ is generated by $\set{\epsilon_j}_{j = 1}^{m}$, then $M \tensor{A} N$ is generated by $e_i \otimes \epsilon_j$.

\begin{prop}
We can also prove that if $e_i, 1 \leq i \leq n$ is a \emph{basis} of $M$ and $\epsilon_j, 1 \leq j \leq m$ is a basis of $N$ (that is, both $M$ and $N$ are free modules over $A$), then $e_i \otimes \epsilon_j, 1 \leq i \leq n, 1 \leq j \leq m$ is a basis of $M \tensor{A} N$. 
\end{prop}
\begin{proof}
This is easily shown with the universal property.
Define a bilinear map $f_{i_0, j_0}: M \times N \to A$ sending $(\sum a_i e_i, \sum b_j \epsilon_j)$ to $a_{i_0}b_{j_0}$.
Since $f_{i_0, j_0}$ is bilinear, it factors through the tensor product $\tilde{f}_{i_0, j_0}: M \tensor{A} N \to A$, where $\tilde{f}_{i_0, j_0}$ sends $e_{i_0} \otimes \epsilon_{j_0}$ to $1$ and all other $e_i \otimes \epsilon_j$ to $0$. So if $\sum \alpha_{ij} e_i \otimes \epsilon_j = 0$, then applying $\tilde{f}_{i_0, j_0}$ we see that $\alpha_{i_0 j_0} = 0$. Doing this for all $i_0, j_0$, we conclude that all coefficients are zero.
\end{proof}

\begin{ex}
In particular, the tensor product of $K$-vector spaces with bases $\set{e_i}$, $\set{\epsilon_j}$ is a $K$-vector space with a base $e_i \otimes \epsilon_j$. 
One usually introduces these symbols formally and builds a vector space on top; however, in general it's better to use the universal property.
\end{ex}

\subsection{Base change.}
We also have other (more or less) elementary properties of the tensor product.

\begin{ex}
For example, we have a sort of associativity: $(M_1 \tensor{A} M_2) \tensor{A} M_3 \iso M_1 \tensor{A} (M_2 \tensor{A} M_3)$. 
To prove this, we introduce $M_1 \tensor{A} M_2 \tensor{A} M_3$ as a universal object for \emph{trilinear} maps, and then show that both parts are isomorphic to this object.
\end{ex}

\begin{dfn}[Base change]
Let $A$ be a ring, $B$ be an $A$-algebra, $M$ and $A$-module, and $N$ a $B$-module. 
We can make $N$ into an $A$-module, by ``forgetting'' the $B$-module structure.
We can ``make'' $M$ into a $B$-module by considering $B \tensor{A} M$.
Introduce the $B$-module structure on $B \tensor{A} M$ by setting $b \cdot (b' \otimes m) = bb' \otimes m$.
\end{dfn}
This may seem sophisticated, but we have certainly encountered some examples before.
\begin{ex}
We can ``make'' $\C^n$ into $\R^{2n}$ by forgetting the complex multiplication: if $\C^n$ has basis $\set{e_i}$, we just forget that we can multiply by the imaginary unit, and so we give $\R^{2n}$ the basis $\set{e_1, \dotsc, e_n, v_1, \dotsc, v_n}$, where $v_i = \imath e_i$. 

If we want to ``complexify'' $\R^{2n}$, we can consider $\C \otimes \R^{2n} = \C^{2n}$ with basis $\set{e_1, \dotsc, e_n, v_1, \dotsc, v_n}$ (forgetting that $v_i = \imath e_i$)---more precisely, one should write $1 \otimes e_1, \dotsc, 1 \otimes e_n, 1 \otimes v_1, \dotsc, 1 \otimes v_n$.

One can go the other way. If $\R^n$ has basis $e_1, \dotsc, e_n$, then we can make it into a complex vector space $\C^n = C \otimes_\R^n$ with a $\C$-basis $1 \otimes e_i$, and make \emph{that} into $\R^{2n}$ by forgetting the complex structure, with an $\R$-basis $1 \otimes e_1, \dotsc, 1 \otimes e_n, \imath \otimes e_1, \dotsc, \imath \otimes e_n$.
\end{ex}

In general, if $M$ is a fee $A$-module with a base $e_1, \dotsc, e_n$, then $B \tensor{A} M$ is a free $B$-module with base $1 \otimes e_1, \dotsc, 1 \otimes e_n$.
We also have maps $M \to B \tensor{A} M, m \mapsto 1 \otimes m$ of $A$-modules; and maps $B \tensor{A} N \to N, b \otimes n \mapsto bn$ of $A$-modules.
The proof of this story about the bases is the same as what we've seen before in Proposition 1: we construct certain bilinear maps that factor over the tensor product, which implies that certain families are linearly independent.

\begin{thm}[Base change]
The $A$-homomorphisms between $M$ and $N$ are in bijection with the $B$-homomorphisms between $B \tensor{A} M$ and $N$. 
(Alternatively, you can say that $\Hom{A}{M, N} \iso \Hom{B}{B \tensor{A} M, N}$ as groups, etc.)
\end{thm}
\begin{proof}
If I have a homomorphism $f: B \tensor{A} M \to N$, we can compose it with the embedding $\alpha: M \to B \tensor{A} M$, so in the one direction we have $f \mapsto f \after \alpha$. 
In the other direction, if we have $g: M \to N$, then we can ``tensor it'' with $B$ to obtain $id \otimes g: B \tensor{A} M \to B \tensor{A} N$.
Then we compose this map with $\mu: B \tensor{A} N \to B$ sending $b \otimes n \mapsto bn$, so we have $g \mapsto \mu \after (id \otimes g)$.
It's easy to check that the maps are mutually inverse.
\end{proof}

\subsection{Examples. Tensor product of algebras.}
Here we give an example of a base change.
\begin{prop}
Let $I \sbs A$ be an ideal (so the ring in question will be $A / I$). Then $A / I \tensor{A} M \iso M / IM$, where $IM$ is a sub-module of $M$.
\end{prop}
\begin{proof}
Define $M \namedmap{\alpha} A/I \otimes M$ by $m \mapsto 1 \otimes m$. This sends $IM$ to zero. 
That is, if we have $im$ where $i \in I$, then $im \mapsto 1 \otimes im$, but the tensor product is over $A$, and so everything is $A$-linear: $1 \otimes im = i \otimes m = 0 \otimes m = 0$.
Hence $\alpha$ induces a map $M / IM \namedmap{\bar\alpha} A/I \tensor{A} M$.

Now, in the other direction, we apply the Base Change Theorem: consider the projection $M \to M / IM$ of $A$-modules.
Setting $B = A/I$, we can then obtain a map $B \tensor{A} M \to M / IM$ of $A$-modules.
We can again check that this map is in fact the inverse of $\bar\alpha$.
\end{proof}

Now we consider some examples.

\begin{ex}[Base-changing rings of integers]
Consider $\Z / 2\Z \tensor{\Z} \Z / 3\Z$. 
Then we can think of this as a base change from $\Z/3\Z$ to $\Z/2\Z$, and so this is isomorphic to $(\Z / 3\Z) / ((2) \cdot \Z / 3\Z)$. 
But $(2)\cdot \Z / 3\Z = \Z / 3\Z$, and so the the quotient is $0$!
\end{ex}
\begin{ex}[Base-changing polynomial rings]
Changing the base of a polynomial ring from $A$ to $B$ just gives a polynomial ring over $B$: $B \tensor{A} A[x] \iso B[x]$
\end{ex}
\begin{ex}[Base-changing quotient rings]
As you might expect from the previous example, $B \tensor{A} A[x] / (P) \iso B[x] / (P)$, but on the RHS $(P)$ is now the ideal generated by $P$ in $B[x]$.
\end{ex}

Now, given two $A$-algebras $B$ and $C$, and $\alpha: A \to B$ (respectively $\beta: A \to C$) defining the $A$-algebra structure on $B$ (respectively $C$), we can define a new $A$-algebra $B \tensor{A} C$.
This is a ring with respect to $(b \otimes c) \cdot (b' \otimes c') = bb' \otimes cc'$.

In fact, this has the following universal property: if $\phi: B \to B \tensor{A} C, b \mapsto b \otimes 1$ and $\psi: C \to B \tensor{A} C, c \mapsto 1 \otimes c$, and $D$ is any $A$-algebra, we have that $\Hom{A}{B \tensor C, D}$ is in bijection with $\Hom{A}(B, D) \times \Hom{A}{C, D}$.
If we have $h: B \tensor{A} C \to D$, this is the same thing as having $B \namedmap{f} D$ and $C \namedmap{g} D$ such that $h = f \times g$ (and the diagram commutes): $h \mapsto (h \after \phi, h \after \psi$, and conversely, given $f, g$, we can define $h(b \otimes c) = f(b) \cdot g(c)$.

The main point for us is that the tensor product of two $A$-algebras is itself an $A$-algebra by componentwise multiplication.

\begin{ex}
Consider $\C \tensor{\R} \C$. Then we have \[ \C \tensor{\R} \C \iso \C \otimes \R[x]/(x^2 + 1) \iso \C[x] / (x^2 + 1) \]
and then by the Chinese Remainder Theorem (see below) we conclude that $\C[x] / (x^2 + 1) \iso \C[x] / (x + \imath) \times \C[x] / (x - \imath)$, which is then isomorphic to $\C \times \C$.
We can then conclude that this tensor product is \emph{not} a field, in particular because it has zero-divisors.
These can be seen, for example, by noticing that the class $\overline{x + \imath}$ is a zero-divisor, which can be represented by $1 \otimes \bar{x} + \imath \otimes \bar{1}$---then in $\C \tensor{\R} \C$ this is just $1 \otimes \imath + \imath \otimes 1 = 0$.
\end{ex}

\subsection{Relatively prime ideals. Chinese Remainder Theorem.}
Now we explore the structure of a finite algebra $A$ over a field $K$. 
(That is, a finite-dimensional vector space.)
First, we recall the Chinese remainder theorem.

\begin{dfn}
Let $A$ be a ring with $I, J$ ideals.
We say that $I$ and $J$ are \term{relatively prime} if $I + J = A$.
\end{dfn}
\begin{lem}
(1) If $I, J$ are relatively prime then $IJ = I \cap J$;
(2) If $I_1, \dotsc, I_k$ are relatively prime to $J$, then so is $\bigcap_{j = 1}^k I_j$;
(3) If $I, J$ are relatively prime then so are $I^k, J^l$ for any $k, l$.
\end{lem}
\begin{proof}[Proof of lemma.]
(1) That $IJ \sbs I \cap J$ is clear; this is just by definition.
Now if $I$ and $J$ are relatively prime, then $1 = i + j$ for some $i \in I$ and $j \in J$.
Hence for any $x \in I \cap J$ we have $x = xi + xj$, and both $xi, xj \in IJ$, so $x \in IJ$.

(2) Suppose that $k = 2$; the general case is similar.
Then we have $1 = i_1 + j_1 = i_2 + j_2$ where $i_1 \in I_1$, $i_2 \in I_2$, and $j_1, j_2 \in J$.
Now write $1 = (i_1 + j_1)(i_2 + j_2) = i_1 i_2 + j_1 i_2 + j_2 i_1 + j_1 j_2$.
We see that $i_1 i_2 \in I_1 I_2$, and $j_1 i_2 + j_2 i_1 + j_1 j_2 \in J$, which is what we want to prove.

Finally, (3) follows from (2) by induction.
\end{proof}
\begin{thm}[Chinese remainder]
Let $I_1, \dotsc, I_n$ be ideals of $A$, and $\pi: A \mapsto A / I_1 \times \dotsb \times A / I_n$, $a \mapsto (a \bmod I_1, \dotsc, a \bmod I_n)$.
(So $\Kernel{\pi} = I_1 \cap \dotsc \cap I_n$). 
Then $\pi$ is surjective if and only if $I_1, \dotsc, I_n$ are pairwise relatively prime.
In this case $A / \bigcap I_k \iso A / \prod I_k \iso \prod \left(A / I_k\right)$.
\end{thm}
\begin{proof}
Suppose $\pi$ is surjective.
Then there exists $a_i$ such that $\pi(a_i) = (0, \dotsc, 0, 1, 0, \dots, 0)$, that is, $1$ in the $i^{th}$ place and all other entries $0$.
This means $a_i \in I_j$ for some $j \neq i$, and $1 - a_i \in I_i$.
Hence $I_i$ is relatively prime to any $I_j$, since $1 = (1 - a_i) + a_i$.

Conversely, suppose that all the ideals are (pairwise) relatively prime; then $I_i$ is relatively prime to $\prod_{j \neq i} I_j$.
Hence there exist $x_i \in I_i, y_i \in \prod_{j \neq i} I_j$ such that $x_i + y_i = 1$.
Such an element $y_i$ maps to $(0, \dotsc, 0, 1, 0, \dotsc, 0)$ with the $1$ in the $i^{th}$ place.
Then $\sum_{i = 1}^{n} b_i y_i \mapsto (b_1, \dotsc, b_n)$ for all $b_i$, and so $\pi$ is surjective.
This proves the theorem.
\end{proof}

Now consider $A$ a finite algebra over $K$. Before proving a general theorem on the structure of $A$, we state proposition.

\begin{prop}
(1) If $A$ is an integral domain, then $A$ is a field;

(2) (rephrasing) Any prime ideal of $A$ is maximal.
\end{prop}
\begin{proof}
It suffices to prove the first part, as the second part is just a consequence of definitions: in fact, a quotient over a prime ideal is an integral domain, and a quotient over a maximal ideal is a field.

Suppose now that $A$ is an integral domain: that is, for any $a \in A$, the multiplication by $a$ is injective.
But $A$ is a finite dimensional $K$-vector space, so this implies that multiplication by $a$ is an isomorphism.
In particular it is surjective, so there exists a $b$ such that $b \cdot a = 1$.
Therefore $A$ is a field, since $1$ has a pre-image, $b$.
\end{proof}

\subsection{Structure of finite algebras over a field. Examples.}
\begin{thm}[Structure of finite $K$-algebras.]
Let $A$ be a finite $K$-algebra (that is, $A$ is a finite dimensional $K$-vector space). Then:

(1) There are only finitely many maximal ideals $\mf{m}_1, \dotsc, \mf{m}_r$ in $A$;

(2) Let $J = \mf{m}_1 \cap \dotsc \cap \mf{m}_r = \mf{m}_1 \times \dotsb \times \mf{m}_r$ (since they are relatively prime).
Then $J^n = 0$ for some $n$;

(3) $A \iso A / \mf{m}_1^{n_1} \times \dotsb A / \mf{m}_r^{n_r}$ for some $n_1, \dotsc, n_r$.
\end{thm}
\begin{proof}
(1) Let $\mf{m}_1, \dotsc, \mf{m}_i$ be maximal ideals. 
By the Chinese remainder theorem, we have $A / \mf{m}_1 \dotsb \mf{m}_i \iso A / \mf{m}_1 \times \dotsb A / \mf{m}_i$. 
Now $A / \mf{m}_1 \dotsb \mf{m}_i$ and any such $A / \mf{m}_j$ are finite-dimensional $K$-vector spaces, and 
\[ \dim_K A \geq \dim_K A / \mf{m}_1 \dotsb \mf{m}_i = \sum_{j = 1}^{i} \dim_K A / \mf{m}_j \geq i\]
So the number of maximal ideals is at most $\dim_K A$; that is, there are only finitely many.

(2) $J$ is also a finite dimensional vector space over $K$, and so are its powers.
Now consider the decreasing sequence $J \spsq J^2 \spsq J^3 \dotsc \spsq J^k \spsq \dotsc$; the dimension is nonincreasing with each step.
Hence the sequence must stabilize; for some $n$ we must have $J^n = J^{n+1}$.
We claim that $J^n = 0$.
Indeed, if not, let $e_1, \dotsc, e_s$ be a basis for $J^n$.
As $J^n = J \cdot J^n$, we can write $e_i = \sum \lambda_{ij}e_j$ for some $\lambda_{ij} \in J$.
If we consider the matrix $M = Id - \lambda_{ij}$ we have that
\[ M \begin{pmatrix} e_1 \\ \vdots \\ e_s \end{pmatrix} = 0 \]
This is just the same as the previous equation.
Since $M$ is a matrix over a ring and not over a field, this does not immediately mean that the $e_i$'s are $0$, but we can always find a matrix $\tilde{M}$ such that $\tilde{M}M = \det{M}\cdot Id$.
Then $\det{M} \cdot (e_1, \dotsc, e_s)^T = 0$, but $\det{M} = 1 + \lambda$ where $\lambda \in J$.
Since $J = \mf{m}_1 \cap \dotsc \cap \mf{m}_r$, $\lambda \in \mf{m}_i$ for all $i$, and so there is no $i$ for which $1 + \lambda \in \mf{m}_i$.
This means that $1 + \lambda$ is invertible, and therefore $e_1 = \dotsb = e_s = 0$, a contradiction.

(3) By part 2, we can find $\mf{m}_1, \dotsc, \mf{m}_r$ such that $\mf{m}_1^{n_1} \dotsb \mf{m}_r^{n_r} = 0$; we can, for example, take $n_i = n$ for all $i$.
Then, by Chinese remainder theorem, since all the $\mf{m}_i^{n_i}$ are pairwise relativel prime, we have 
\[ A / \mf{m}_1^{n_1} \dotsb \mf{m}_r^{n_r} = A \iso A / \mf{m}_1^{n_1} \times \dotsb \times A / \mf{m}_r^{n_r} \]
This proves the theorem.
\end{proof}
\begin{rmk}
The $n_i$'s are \emph{not} uniquely determined; we could have taken all of them equal to $n$, but we can also write this identity with at least some $n_i$'s different from $n$.
For instance, let $A = K[x] / (x^2 \cdot (x + 1)^3)$. Then $\mf{m}_1 = (x), \mf{m}_2 = (x + 1)$, and $A \iso A / \mf{m}_1^2 \times A / \mf{m}_2^3$, but also $A \iso A / \mf{m}_1^3 \times A / \mf{m}_2^3$.
The reason is very simple: in fact $\mf{m}_1^2 = \mf{m}_1^3$.
In $A$, we have $(x)^2 \sps (x)^3$ but \emph{also} $(x)^3 \sps (x)^2$; this is true in $A$ but not in the polynomial ring, and the verification is left as an exercise.
\end{rmk}

Now we consider some examples.
\begin{ex}
$\C \tensor{\R} \C \iso \C \times \C$; $\Q(\sqrt{2}) \tensor{\Q} \Q(\sqrt{3}) = \Q(\sqrt{2}, \sqrt{3})$. 
These algebras are products of fields; all $n_i = 1$ (in other words, we do not have nilpotents, so these are \term{reduced} algebras).
\end{ex}

This is a general phenomenon: the presence of nilpotents is due to the \emph{inseparability} of extensions.